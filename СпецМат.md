# Теория вероятностей
**Монетка**:
$\Omega = \{ \text{О}; \text{Р} \}$. $\Omega$ - множество элементарных исходов; $\leqslant$ счетное.

Случайное событие: $A \subset \Omega$.
$P: \Omega \rightarrow \mathbb{R}_+$:
1. $P(x) \geqslant 0$
2. $\sum\_{x \in \Omega} P(x) = 1$

$(\Omega, P)$ - вероятностное пространство.
Вероятность события $A$ - $P(A) = \sum_{x \in A} P(x)$.
**Случайное событие** - измеримое подмножество вероятностного пространства.
Сумма событий - объединение множеств.
$P(A + B) = P(A) + P(B) - P(AB)$
$P(A + B + C) = P(A) + P(B) + P(C) - P(AB) - P(BC) - P(AC) + P(ABC)$
**Опр.** $A$ и $B$ называются независимыми, если $P(AB) = P(A) \cdot P(B)$.
Пример:
$\Omega_1$ и $\Omega_2$ - вероятностные пространства.
 $\Omega_1 \times \Omega_2$ - вероятностное пространство.
 $A \subset \Omega_1$ - случайное событие.
 $P(x, y) = P_1(x) \cdot P_2(y)$.
 $P_1(A) = P(A \times \Omega_2)$.

$AB \leftrightarrow (A \times \Omega_2) \cap (\Omega_1 \times B) = A \times B$.
$A, B, C$ - независимы, если $P(ABC) = P(A)P(B)P(C)$.
Cобытия $A_1, A_2, \dots A_n$ независимы, если $\forall A_{i1}, \dots, A_{ik}$ верно $P(A_{i1}A_{i2} \dots A_{ik}) = \text{П}^k_{j = 1} P(A_{ij})$.
**Опр.** Условная вероятность. $P(A|B)$ - вероятность $A$ при условие, что $B$ произошло.
**Теорема.** Формула полной вероятности. Пусть $A_1, A_2, \dots, A_n$ - система попарно несовместимых событий, в сумме дающих достоверное. Тогда для любого события $B$ выполнена формула $P(A) = \sum_{i = 1}^{k} P(A|B_i) \cdot P(B_i)$. Доказательство:
$P(A|B) = \frac{P(AB)}{P(B)}$.
$P(A) = \sum_{i = 1}^{k} P(AB_i)$.
## Случайные величины
**Опр.** $\Omega$ - вероятностное пространство, $f: \Omega \rightarrow \mathbb{R}$. $f$ называется случайной величиной.
**Пример**:
Бросаем кубик. $\Omega = {1, 2, 3, 4, 5, 6}$, $p(x) = \frac{1}{6}$. $f(1) = 1, f(2) = 2$, и т. д.
На $\mathbb{R}$ введем структуру вероятностного пространства: $1 - \frac{1}{6}, 2 - \frac{1}{6}, 3 - \frac{1}{6}, 4 - \frac{1}{6}, 5 - \frac{1}{6}, 6 - \frac{1}{6}$, остальные $0$.

**Опр.** $f: \Omega \rightarrow \mathbb{R} \Rightarrow$ на $\mathbb{R}$ вводится структура вероятностного пространства. $\forall x \in \mathbb{R}$ $P_{\mathbb{R}}(x) = P_{\Omega}(f^{-1}(x))$.
**Опр.** Распределение случайной величины $f$ - структура вероятностного пространства на $\mathbb{R}$.
**Стандартное распределение**:
1. Дискретное равномерное. $x_1 - \frac{1}{n}, x_2 - \frac{1}{n}, \dots, x_n - \frac{1}{n}$.
2. Распределение Бернулли.
$f(x) = \begin{cases} 1 & p \\ 0 & q = 1 - p \end{cases}$
3. Биномиальное распределение. $f = f_1 + f_2 + \dots + f_n$, где $f_i$ - распределение Бернулли.
$\sum = q^n + C_n^1q^{n - 1}p + \dots + p^n = (q + p)^n$
$P(f = k) = C_n^k p^k q^{n - k}$
4. Геометрическое распределение. Бросаем неравновесную монетку до выпадения орла. Случайная величина - количество испытаний.
$P(f(x) = k) = q^{k - 1} \cdot p$.
5. Распределение Пуассона.
$P(f = k) = \frac{\lambda^k}{k!} \cdot e^{-\lambda}$. $e \approx 2.718281828459045$, $\lambda > 0$.
6. Гипергеометрическое распределение. В сосуде $N$ белых шаров и $M$ черных. Мы не глядя вытаскиваем $n$ шаров без возвращения. Случайная величина - количество белых шаров.
$P(f = k) = \frac{C_N^k \cdot C_M^{n - k}}{C_{N + M}^n}$.

**Опр.** Сложение. $f: \Omega \rightarrow \mathbb{R}$, $g: \Omega \rightarrow \mathbb{R}$. $(f + g)(x) = f(x) + g(x)$.
**Опр.** $f(x) = a$ - случайное событие.
**Опр.** $f$ и $g$ независимые, если $\forall A, B \in \mathbb{R}: P(f(x) \in A; g(x) \in B) = P(f(x) \in A) \cdot P(g(x) \in B)$. Или: $P(f(x) = a; g(x) = b) = P(f(x) = a) \cdot P(g(x) = b)$.
## Математическое ожидание
**Опр.** $f$ - случайная величина. Ее математическим ожиданием называется $Mf = Ef = \sum_{x \in \Omega} f(x)P(x)$.
Свойства:
1. $c$ - константа это случайная величина.
$Mc = c$.
2. $f_1 \leqslant f_2 ( \Leftrightarrow f_1(x) \leqslant f_2(x) \forall x)$
$\Rightarrow Mf_1 \leqslant Mf_2$.
3. $M(cf) = c \cdot Mf$.
4. $M(f_1 + f_2) = Mf_1 + Mf_2$.
$\sum_{x \in \Omega} (f_1(x) + f_2(x))P(x) = \sum f_1(x) \cdot P(x) + \sum f_2(x) \cdot P(x)$
5. Если $f_1, f_2$ - независимы $\Rightarrow M(f_1 \cdot f_2) = Mf_1 \cdot Mf_2$.
$M(f_1 \cdot f_2) = \sum_{x \in \Omega} f_1(x) \cdot f_2(x) \cdot P(x) = \sum a_i \cdot b_j \cdot P(f_1 = a_i; f_2 = b_j) = \sum_{i, j} a_i \cdot b_j \cdot P(f_1 = a_i) \cdot P(f_2 = b_j) =$
$= \sum_i a_i \cdot P(f_1 = a_i) \cdot \sum_j b_j \cdot P(f_2 = b_j) = Mf_1 \cdot Mf_2$.
$P(f = k) = \frac{C_M^k \cdot C_N^{n - k}}{C_{M + N}^n}$.
$Mf = \frac{n \cdot M}{M + N}$.
$Mf = \sum_{k = 0}^n \frac{k \cdot C_M^k \cdot C_N^{n - k}}{C_{M + N}^n} = \frac{n \cdot M}{M + N} \cdot \frac{(M - 1)!N!(n - 1)!(M + N - n)!}{(M + N - 1)!} \sum_{k = 0}^n \frac{1}{(k - 1)!(M - k)!(n - k)!(N - n + k)!}$
$\sum_{k = 0}^n \frac{(M - 1)!N!(n - 1)!(M + N - n)!}{(k - 1)!(M - k)!(n - k)!(N - n + k)!(M + N - 1)!} = \sum_{k = 0}^N \frac{C_{n - 1}^{k - 1} \cdot C_{M + N - n}^{M - k}}{C_{M + N - 1}^{M - 1}} = 1$.
## Дисперсия
**Опр.** Мера отклонения случайной величины от своего математического ожидания. $f$ - случайная величина; $Df = M(f - Mf)^2$.
**Опр.** Центрирование случайной величины - $M(f - Mf) = Mf - M(Mf) = 0$. Условно сдвигаем систему координат в $0$.
$Df = M(f^2 - 2f \cdot Mf + (Mf)^2) = Mf^2 - 2M^2f + M(M^2f) = Mf^2 - M^2f$.
Свойства:
1. $D(c) = 0$
$D(f) = 0 \Rightarrow f = const$
2. $D(cf) = c^2 D(f)$
3. $D(f + c) = Df$
4. Если случайные величины $f$ и $g$ независимы, то $D(f + g) = Df + Dg$
**Формула Стирлинга**. $n! \approx \sqrt{2\pi n} \cdot (\frac{n}{e})^n \cdot e^{\frac{\theta_n}{12n}}$. При больших $n$, $e^{\frac{\theta_n}{12n}} \approx 1$.